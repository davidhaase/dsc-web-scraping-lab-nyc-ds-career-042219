{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've seen a more extensive example of developing a web scraping script, it's time to further practice and formalize that knowledge by writing functions to parse specific pieces of information from the web page and then synthesizing these into a larger loop that will iterate over successive web pages in order to build a complete dataset.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Write functions to parse specific information from a web page\n",
    "* Iterate over successive web pages in order to create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Overview\n",
    "\n",
    "This lab will build upon the previous lesson. In the end, you'll look to write a script that will iterate over all of the pages for the demo site and extract the title, price, star rating and availability of each book listed. Building up to that, you'll formalize the concepts from the lesson by writing functions that will extract a list of each of these features for each web page. You'll then combine these functions into the full script which will look something like this:  \n",
    "\n",
    "```python\n",
    "df = pd.DataFrame()\n",
    "for i in range(2,51):\n",
    "    url = \"http://books.toscrape.com/catalogue/page-{}.html\".format(i)\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    new_titles = retrieve_titles(soup)\n",
    "    new_star_ratings = retrieve_ratings(soup)\n",
    "    new_prices = retrieve_prices(soup)\n",
    "    new_avails = retrieve_avails(soup)\n",
    "    ...\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Titles\n",
    "\n",
    "To start, write a function that extracts the titles of the books on a given page. The input for the function should be the `soup` for the HTML of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    try:\n",
    "        r = requests.get(home_url) \n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return BeautifulSoup(r.content, 'html.parser') \n",
    "\n",
    "def get_cat_pages(url, soup):\n",
    "    urls = {}\n",
    "\n",
    "    for link in soup.find_all('a'):\n",
    "        prefix = 'catalogue/category/books/'\n",
    "        cat_url = link.get('href')\n",
    "        if prefix in cat_url:            \n",
    "            urls[link.get_text().strip()] = url + cat_url\n",
    "\n",
    "    return urls\n",
    "\n",
    "def get_products(soup):\n",
    "    products = soup.find_all(class_='product_pod')\n",
    "    books = []\n",
    "    for product in products:\n",
    "        books.append(Book(product))\n",
    "    \n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book:\n",
    "    ratings = ['', 'One', 'Two', 'Three', 'Four', 'Five']\n",
    "    currencies = ['$', '£']\n",
    "    def __init__(self, soup_excerpt):\n",
    "        self.base_url = ''\n",
    "        self.soup = soup_excerpt\n",
    "        self.image_path = soup_excerpt.find('img').attrs['src']\n",
    "        self.title = soup_excerpt.find('h3').a.get('title')\n",
    "        self.rating_str = soup_excerpt.find('p').get('class')\n",
    "        self.rating = int(self.ratings.index(self.rating_str[1]))\n",
    "        self.price_str = soup_excerpt.find('p', class_='price_color').text\n",
    "        self.price_float = float(self.price_str[1:])\n",
    "        self.availability = soup_excerpt.find('p', class_='instock availability').text.strip()\n",
    "        self.currency = self.price_str[0]\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return {'title': self.title,\n",
    "                'price': self.price_float,\n",
    "               'rating': self.rating,\n",
    "               'availablility': self.availability,\n",
    "               'image_path': self.image_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Ratings\n",
    "\n",
    "Next, write a similar function to retrieve the star ratings on a given page. Again, the function should take in the `soup` from the given html page and return a list of the star-ratings for the books. These star ratings should be formatted as integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Prices\n",
    "\n",
    "Now write a function to retrieve the prices on a given page. The function should take in the `soup` from the given page and return a list of prices formatted as floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Availability\n",
    "\n",
    "Write a function to retrieve whether each book is available or not. The function should take in the `soup` from a given html page and return a list of the availability for each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for titles in Travel\n",
      "Searching for titles in Mystery\n",
      "Searching for titles in Historical Fiction\n",
      "Searching for titles in Sequential Art\n",
      "Searching for titles in Classics\n",
      "Searching for titles in Philosophy\n",
      "Searching for titles in Romance\n",
      "Searching for titles in Womens Fiction\n",
      "Searching for titles in Fiction\n",
      "Searching for titles in Childrens\n",
      "Searching for titles in Religion\n",
      "Searching for titles in Nonfiction\n",
      "Searching for titles in Music\n",
      "Searching for titles in Default\n",
      "Searching for titles in Science Fiction\n",
      "Searching for titles in Sports and Games\n",
      "Searching for titles in Add a comment\n",
      "Searching for titles in Fantasy\n",
      "Searching for titles in New Adult\n",
      "Searching for titles in Young Adult\n",
      "Searching for titles in Science\n",
      "Searching for titles in Poetry\n",
      "Searching for titles in Paranormal\n",
      "Searching for titles in Art\n",
      "Searching for titles in Psychology\n",
      "Searching for titles in Autobiography\n",
      "Searching for titles in Parenting\n",
      "Searching for titles in Adult Fiction\n",
      "Searching for titles in Humor\n",
      "Searching for titles in Horror\n",
      "Searching for titles in History\n",
      "Searching for titles in Food and Drink\n",
      "Searching for titles in Christian Fiction\n",
      "Searching for titles in Business\n",
      "Searching for titles in Biography\n",
      "Searching for titles in Thriller\n",
      "Searching for titles in Contemporary\n",
      "Searching for titles in Spirituality\n",
      "Searching for titles in Academic\n",
      "Searching for titles in Self Help\n",
      "Searching for titles in Historical\n",
      "Searching for titles in Christian\n",
      "Searching for titles in Suspense\n",
      "Searching for titles in Short Stories\n",
      "Searching for titles in Novels\n",
      "Searching for titles in Health\n",
      "Searching for titles in Politics\n",
      "Searching for titles in Cultural\n",
      "Searching for titles in Erotica\n",
      "Searching for titles in Crime\n"
     ]
    }
   ],
   "source": [
    "home_url = 'http://books.toscrape.com/'\n",
    "soup = get_soup(home_url)\n",
    "cat_urls = get_cat_pages(home_url, soup)\n",
    "\n",
    "products = []\n",
    "\n",
    "# products = get_products(get_soup(cat_urls['Travel']))\n",
    "for category in cat_urls:\n",
    "    print('Searching for titles in {}'.format(category))\n",
    "    products += get_products(get_soup(cat_urls[category]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Script to Retrieve All the Books From All 50 Pages\n",
    "\n",
    "Finally, write a script to retrieve all of the information from all 50 pages of the books.toscrape.com website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'£'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[0].currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.0485"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([product.to_dict() for product in products])\n",
    "df.shape\n",
    "df.price.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level-Up: Write a new version of the script you just wrote. \n",
    "\n",
    "If you used url hacking to generate each successive page url, instead write a function that retrieves the link from the `\"next\"` button at the bottom of the page. Conversely, if you already used this approach above, use URL-hacking (arguably the easier of the two methods in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! You just completed your first full web scraping project! You're ready to start harnessing the power of the web!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
